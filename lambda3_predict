import json
import time
import boto3
import os
import urllib.parse

def lambda_handler(event, context):
    # Retrieve the S3 bucket name and object key from the event
    # s3_bucket = event['Records'][0]['s3']['bucket']['name']
    # object_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    

    # Specify your EC2 instance ID
    instance_id = 'id'

    # Create an SSM client
    ssm = boto3.client('ssm')
    

    try:
        
        # Run the command to copy the file from S3 to the EC2 instance
        
        response = ssm.send_command(
            InstanceIds=[instance_id],
            DocumentName="AWS-RunShellScript",
            Parameters={
                'commands': ['cd /home/ubuntu/','python3 predict.py > r.txt']
                           }
        )

        command_id = response["Command"]["CommandId"]

        # Wait for the command to complete
        time.sleep(5)
        response = ssm.send_command(
            InstanceIds=[instance_id],
            DocumentName="AWS-RunShellScript",
            Parameters={
                'commands': ['aws s3 cp /home/ubuntu/r.txt s3://divyareddybucket/result/r.txt']
                           }
        )
        
        
        # Fetch the command output
        output = ssm.get_command_invocation(CommandId=command_id, InstanceId=instance_id)

        # Print the command output
        print(output)
        
        # return {"statusCode": 200, "body": json.dumps("File analizedd successfully.")}

    
        print("Prediction done")
        
        
       
        return {
            'statusCode': 200,
            'body': 'Files analized successfully'
        }
        
    except Exception as e:
        print(f"Error copying file: {e}")
        return {"statusCode": 500, "body": json.dumps("Failed to delete.")}

