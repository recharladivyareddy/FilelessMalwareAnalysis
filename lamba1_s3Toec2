import json
import time
import boto3
import os
import urllib.parse

def lambda_handler(event, context):
    # Retrieve the S3 bucket name and object key from the event
    s3_bucket = event['Records'][0]['s3']['bucket']['name']
    object_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    # Split the object key to get the file name
    file_name = object_key.split('/')[-1]

    # Print the file name
    print("Bucket name:",s3_bucket)
    print("Object_key:",object_key)
    print("Uploaded file name:", file_name)
    
    # Specify your EC2 instance ID
    instance_id = <ID>

    # Create an SSM client
    ssm = boto3.client('ssm')
    
    instance_id='id'
    
    ec2 = boto3.client('ec2')
    ec2.start_instances(InstanceIds=[instance_id])
    print("Instane successfully started")
    
    #Wait until instance comes from pending state to started state
    while True:
        
        instance_state = ec2.describe_instances(InstanceIds=['id'])['Reservations'][0]['Instances'][0]['State']['Name']
        if instance_state == 'running' :
            break
        time.sleep(5)
    while True:
        response = ec2.describe_instance_status(InstanceIds=['id'])
        instance_status = response['InstanceStatuses'][0]
        system_status = response['InstanceStatuses'][0]['SystemStatus']
        
        instance_status_check = instance_status['InstanceStatus']['Details'][0]
        system_status_check = system_status['Details'][0]
        
        if instance_status_check['Status'] == 'passed' and system_status_check['Status'] == 'passed':
            break
        time.sleep(3)
        
    print("Instance Status Check:")
    print("Type:", instance_status_check['Name'])
    print("Status:", instance_status_check['Status'])
    print()
    print("System Status Check:")
    print("Type:", system_status_check['Name'])
    print("Status:", system_status_check['Status'])
    

    try:
        # Run the command to copy the file from S3 to the EC2 instance
        response = ssm.send_command(
            InstanceIds=[instance_id],
            DocumentName="AWS-RunShellScript",
            Parameters={
                'commands': [ 'aws s3 cp s3://{}/{} /home/ubuntu/{}'.format(s3_bucket, object_key,file_name),
                    'unzipped_file=$(sudo unzip -Z -1 /home/ubuntu/{})'.format(file_name),
                    'sudo unzip -o /home/ubuntu/{} -d /home/ubuntu'.format(file_name),
                    'sleep 1',
                     'aws s3 cp /home/ubuntu/"$unzipped_file" Bucket_Path']
                # 'sudo bash bashscript.sh cridex.vmem']
            }
        )

        command_id = response["Command"]["CommandId"]

        # Wait for the command to complete
        time.sleep(5)

        # Fetch the command output
        output = ssm.get_command_invocation(CommandId=command_id, InstanceId=instance_id)

        # Print the command output
        print(output)

        return {"statusCode": 200, "body": json.dumps("File copied successfully.")}

    except Exception as e:
        print(f"Error copying file: {e}")
        return {"statusCode": 500, "body": json.dumps("Failed to copy the file.")}
