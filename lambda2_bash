import json
import time
import boto3
import os
import urllib.parse

def lambda_handler(event, context):
    # Retrieve the S3 bucket name and object key from the event
    s3_bucket = event['Records'][0]['s3']['bucket']['name']
    object_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    # Split the object key to get the file name
    file_name = object_key.split('/')[-1]

    # Print the file name
    print("Bucket name:",s3_bucket)
    print("Object_key:",object_key)
    print("Uploaded file name:", file_name)
    
    
    # Specify your EC2 instance ID
    instance_id = 'i-0f1fabc499485d88a'

    # Create an SSM client
    ssm = boto3.client('ssm')
    
    instance_id='i-0f1fabc499485d88a'

    try:
        # Run the command to copy the file from S3 to the EC2 instance
        response = ssm.send_command(
            InstanceIds=[instance_id],
            DocumentName="AWS-RunShellScript",
            Parameters={
                'commands': ['cd /home/ubuntu/','bash /home/ubuntu/bashscript.sh {}'.format(file_name)]
                           }
        )

        command_id = response["Command"]["CommandId"]

        # Wait for the command to complete
        time.sleep(50)

        # Fetch the command output
        output = ssm.get_command_invocation(CommandId=command_id, InstanceId=instance_id)

        # Print the command output
        print(output)

        return {"statusCode": 200, "body": json.dumps("File analizedd successfully.")}

    except Exception as e:
        print(f"Error copying file: {e}")
        return {"statusCode": 500, "body": json.dumps("Failed to copy the file.")}
