import json
import time
import boto3
import os
import urllib.parse

def lambda_handler(event, context):
    # Retrieve the S3 bucket name and object key from the event
    s3_bucket = event['Records'][0]['s3']['bucket']['name']
    object_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    

    # Specify your EC2 instance ID
    instance_id = <ID>

    # Create an SSM client
    ssm = boto3.client('ssm')
    
    time.sleep(5)

    try:
        
        
        # Specify your S3 bucket and folder path
        
        bucket_name=<BUCKET_PATH>
        folder_path1 = 'zipfile/'
        folder_path2 = 'memorydump/'
        folder_path3 = 'attributes/'
    
        # Create an S3 client
        s3 = boto3.client('s3')
        
        response1 = s3.list_objects(Bucket=bucket_name, Prefix=folder_path1)
    
        # Extract the file keys from the response
        file_keys1 = [obj['Key'] for obj in response1.get('Contents', [])]
        print(file_keys1)
        
        response2 = s3.list_objects(Bucket=bucket_name, Prefix=folder_path2)
    
        # Extract the file keys from the response
        file_keys2 = [obj['Key'] for obj in response2.get('Contents', [])]
        print(file_keys2)
        
        
        res = ssm.send_command(
            InstanceIds=<ID>,
            DocumentName="AWS-RunShellScript",
            Parameters={
                'commands': ['cd /home/ubuntu/','sudo rm modified.txt','sudo rm r.txt','sudo rm {}'.format(file_keys1[1].split('/')[-1]),'sudo rm {}'.format(file_keys2[1].split('/')[-1])]
                           }
        )

        command_id = res["Command"]["CommandId"]
        time.sleep(5)
        
        # Fetch the command output
        out = ssm.get_command_invocation(CommandId=command_id, InstanceId=instance_id)

        # Print the command output
        print(out)
        
    
        def delete_files_in_folder(bucket_name, folder_name):
            s3 = boto3.resource('s3')
        
            # Iterate over the objects in the specified folder
            bucket = s3.Bucket(bucket_name)
            objects_to_delete = []
            for obj in bucket.objects.filter(Prefix=folder_name):
                if obj.key != folder_name:  # Skip the folder itself
                    objects_to_delete.append({'Key': obj.key})
            
            # Delete the objects
            if len(objects_to_delete) > 0:
                bucket.delete_objects(Delete={'Objects': objects_to_delete})
        
        delete_files_in_folder(bucket_name, folder_path1)
        delete_files_in_folder(bucket_name, folder_path2)
        delete_files_in_folder(bucket_name, folder_path3)
        
        
        
    
        return {
            'statusCode': 200,
            'body': 'Files deleted successfully'
        }
        
    except Exception as e:
        print(f"Error copying file: {e}")
        return {"statusCode": 500, "body": json.dumps("Failed to delete.")}


